{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aarongonzalezoxed/OTCC-MOCK-V2/blob/main/LTE_MOCK_ADULTOS_LAST_UPDATE_22_01_25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DATA MANAGEMENT / OTCC MOCK ADULTOS\n",
        "\n",
        "import io, re, os\n",
        "from datetime import datetime, timezone\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "AUTO_DOWNLOAD = True\n",
        "try:\n",
        "    from google.colab import files\n",
        "except Exception:\n",
        "    files = None\n",
        "\n",
        "print(\"Sube los reportes de AssessmentQ (puedes seleccionar varios; .csv, .xlsx o .xls).\")\n",
        "if files:\n",
        "    uploaded = files.upload()\n",
        "else:\n",
        "    raise RuntimeError(\"Ejecuta esto en Google Colab.\")\n",
        "\n",
        "# ====== Tabla de máximos (MOCK) ======\n",
        "max_scores_map = {\n",
        "    ('A1','USE OF ENGLISH'): 400, ('A1','READING'): 200, ('A1','LISTENING'): 200, ('A1','WRITING'): 200,\n",
        "    ('A2','USE OF ENGLISH'): 400, ('A2','READING'): 200, ('A2','LISTENING'): 200, ('A2','WRITING'): 200,\n",
        "    ('B1','USE OF ENGLISH'): 400, ('B1','READING'): 280, ('B1','LISTENING'): 240, ('B1','WRITING'): 200,\n",
        "    ('B2','USE OF ENGLISH'): 400, ('B2','READING'): 280, ('B2','LISTENING'): 240, ('B2','WRITING'): 200,\n",
        "    ('C1','USE OF ENGLISH'): 400, ('C1','READING'): 200, ('C1','LISTENING'): 240, ('C1','WRITING'): 300,\n",
        "    ('C2','USE OF ENGLISH'): 400, ('C2','READING'): 200, ('C2','LISTENING'): 320, ('C2','WRITING'): 300,\n",
        "}\n",
        "\n",
        "# ====== Utilidades ======\n",
        "def read_any_table(fname: str, data: bytes) -> pd.DataFrame:\n",
        "    lower = fname.lower()\n",
        "    if lower.endswith((\".xlsx\", \".xls\")):\n",
        "        return pd.read_excel(io.BytesIO(data), header=None, dtype=str, engine=\"openpyxl\")\n",
        "    try:\n",
        "        return pd.read_csv(io.BytesIO(data), header=None, sep=None, engine=\"python\", encoding=\"utf-8\", dtype=str)\n",
        "    except Exception:\n",
        "        return pd.read_csv(io.BytesIO(data), header=None, sep=None, engine=\"python\", encoding=\"latin-1\", dtype=str)\n",
        "\n",
        "def extract_exam_label_B1(df_raw: pd.DataFrame) -> str:\n",
        "    try:\n",
        "        return str(df_raw.iat[0,1]).strip()\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "def parse_exam_fields(exam_label: str):\n",
        "    level, group_id = None, None\n",
        "    m = re.search(r'OTCC\\s+MOCK\\s+([ABC]\\d)\\b', exam_label, re.IGNORECASE)\n",
        "    if m: level = m.group(1).upper()\n",
        "    g = re.search(r'\\(([^)]+)\\)', exam_label)\n",
        "    if g: group_id = g.group(1).strip()\n",
        "    return level, group_id\n",
        "\n",
        "def set_header_row4(df_raw: pd.DataFrame):\n",
        "    if df_raw.shape[0] < 4:\n",
        "        raise ValueError(\"El archivo no trae al menos 4 filas (esperada cabecera en fila 4).\")\n",
        "    header = df_raw.iloc[3].astype(str).tolist()\n",
        "    df = df_raw.iloc[4:].copy()\n",
        "    df.columns = header\n",
        "    return df\n",
        "\n",
        "# Partes / columnas (MOCK)\n",
        "PARTS = {\"USE OF ENGLISH\": 2, \"READING\": 3, \"LISTENING\": 4, \"WRITING\": 5}\n",
        "COL_SCORE   = \"Part {n}- Score\"\n",
        "COL_PERCENT = \"Part {n}- Score(%)\"\n",
        "\n",
        "ID_COLS = {\n",
        "    \"user_id\": [\"User Id\",\"User ID\",\"UserId\",\"Userid\"],\n",
        "    \"first\":   [\"First Name\",\"Firts Name\",\"Firstname\",\"First name\"],\n",
        "    \"last\":    [\"Last Name\",\"Lastname\",\"Last name\"],\n",
        "}\n",
        "def find_first_present(df_cols, candidates):\n",
        "    for c in candidates:\n",
        "        if c in df_cols: return c\n",
        "    lower = {c.lower(): c for c in df_cols}\n",
        "    for c in candidates:\n",
        "        if c.lower() in lower: return lower[c.lower()]\n",
        "    return None\n",
        "\n",
        "def to_num(x):\n",
        "    try: return float(str(x).replace('%','').replace(',','').strip())\n",
        "    except: return np.nan\n",
        "\n",
        "def pct_two_dec_str(x):\n",
        "    if x is None or (isinstance(x,float) and np.isnan(x)):\n",
        "        return \"N/A\"\n",
        "    return f\"{round(float(x),2):.2f}%\"\n",
        "\n",
        "def sanitize_png_name(name):\n",
        "    return re.sub(r'[\\\\/*?:\\\"<>|]+','_', name).strip()\n",
        "\n",
        "def unified_csv_name():\n",
        "    ts = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%S\")\n",
        "    return f\"OTCC MOCK - UNIFICADO_{ts}.csv\"\n",
        "\n",
        "# ====== NUEVO ORDEN / NUEVAS COLUMNAS ======\n",
        "CSV_COLS = [\n",
        "    \"User ID\",\n",
        "    \"Test name\",\n",
        "    \"Full name\",\n",
        "    \"Applied level\",\n",
        "    \"Use of English\",\n",
        "    \"Reading\",\n",
        "    \"Listening\",\n",
        "    \"Writing\",\n",
        "    \"Score Obtained\",\n",
        "    \"Level Achieved\",\n",
        "    \"Passing Criteria\",\n",
        "]\n",
        "\n",
        "invalid_files = []\n",
        "fallback_missing_max = []\n",
        "master_rows, console_overall_rows = [], []\n",
        "acc = {\"USE OF ENGLISH\": [], \"READING\": [], \"LISTENING\": [], \"WRITING\": [], \"OVERALL\": []}\n",
        "\n",
        "# Ahora la distribución debe ser por Level Achieved (incluyendo N/A)\n",
        "level_counts = {}\n",
        "level_order = [\"A1\",\"A2\",\"B1\",\"B2\",\"C1\",\"C2\",\"N/A\"]\n",
        "\n",
        "def level_one_below(level):\n",
        "    base_order = [\"A1\",\"A2\",\"B1\",\"B2\",\"C1\",\"C2\"]\n",
        "    if level not in base_order:\n",
        "        return level\n",
        "    idx = base_order.index(level)\n",
        "    return base_order[max(0, idx-1)]\n",
        "\n",
        "def compute_level_achieved(applied_level, score_obtained):\n",
        "    if applied_level is None or score_obtained is None or (isinstance(score_obtained,float) and np.isnan(score_obtained)):\n",
        "        return None\n",
        "\n",
        "    s = float(score_obtained)\n",
        "\n",
        "    # C2 reglas especiales\n",
        "    if applied_level == \"C2\":\n",
        "        if s >= 80:\n",
        "            return \"C2\"\n",
        "        elif 70 <= s <= 79.999999:\n",
        "            return \"C1\"\n",
        "        else:\n",
        "            return \"B2\"\n",
        "\n",
        "    # A1–C1\n",
        "    if s >= 70:\n",
        "        return applied_level\n",
        "    else:\n",
        "        # si es A1, se queda A1\n",
        "        if applied_level == \"A1\":\n",
        "            return \"A1\"\n",
        "        return level_one_below(applied_level)\n",
        "\n",
        "def compute_passing_criteria(applied_level, score_obtained):\n",
        "    if applied_level is None or score_obtained is None or (isinstance(score_obtained,float) and np.isnan(score_obtained)):\n",
        "        return \"N/A\"\n",
        "\n",
        "    s = float(score_obtained)\n",
        "    threshold = 80.0 if (applied_level == \"C2\") else 70.0\n",
        "\n",
        "    if s >= threshold:\n",
        "        return \"PASSED\"\n",
        "    else:\n",
        "        # Regla especial A1: no hay nivel abajo, queda FAILED\n",
        "        if applied_level == \"A1\":\n",
        "            return \"FAILED\"\n",
        "        return \"1LB\"\n",
        "\n",
        "# ====== Proceso de todos los archivos ======\n",
        "for fname, content in uploaded.items():\n",
        "    try:\n",
        "        df_raw = read_any_table(fname, content)\n",
        "        exam_label = extract_exam_label_B1(df_raw)\n",
        "        if not exam_label or not exam_label.upper().startswith(\"OTCC MOCK\"):\n",
        "            invalid_files.append(fname); continue\n",
        "\n",
        "        level_from_name, group_id = parse_exam_fields(exam_label)\n",
        "        df = set_header_row4(df_raw)\n",
        "\n",
        "        user_id_col = find_first_present(df.columns, ID_COLS[\"user_id\"])\n",
        "        fn_col      = find_first_present(df.columns, ID_COLS[\"first\"])\n",
        "        ln_col      = find_first_present(df.columns, ID_COLS[\"last\"])\n",
        "        if not user_id_col or not fn_col or not ln_col:\n",
        "            raise ValueError(\"Faltan columnas de identidad (User/First/Last).\")\n",
        "\n",
        "        # Overall del reporte (puede variar el encabezado en algunos archivos)\n",
        "        overall_report_col = \"Score (%)\"\n",
        "        if overall_report_col not in df.columns:\n",
        "            for alt in [\"Score(%)\",\"Overall Score (%)\",\"Total Score (%)\",\"Overall (%)\",\"Total (%)\"]:\n",
        "                if alt in df.columns:\n",
        "                    overall_report_col = alt\n",
        "                    break\n",
        "            else:\n",
        "                overall_report_col = None\n",
        "\n",
        "        cnt = 0\n",
        "        for _, row in df.iterrows():\n",
        "            user_id    = str(row.get(user_id_col, \"\")).strip()\n",
        "            first_name = str(row.get(fn_col, \"\")).strip()\n",
        "            last_name  = str(row.get(ln_col, \"\")).strip()\n",
        "            full_name  = (first_name + \" \" + last_name).strip()\n",
        "\n",
        "            # Recalcular por habilidad\n",
        "            skill_calc, skill_native = {}, {}\n",
        "            for skill, part_n in PARTS.items():\n",
        "                score_col = COL_SCORE.format(n=part_n)\n",
        "                pct_col   = COL_PERCENT.format(n=part_n)\n",
        "                raw_points     = to_num(row.get(score_col, np.nan))\n",
        "                raw_pct_native = to_num(row.get(pct_col,   np.nan))\n",
        "                skill_native[skill] = None if np.isnan(raw_pct_native) else raw_pct_native\n",
        "\n",
        "                calc_pct = np.nan\n",
        "                key = (level_from_name, skill)\n",
        "                if level_from_name and key in max_scores_map and not np.isnan(raw_points):\n",
        "                    max_sc = max_scores_map[key]\n",
        "                    if max_sc and max_sc > 0:\n",
        "                        calc_pct = (raw_points / max_sc) * 100.0\n",
        "                if np.isnan(calc_pct):\n",
        "                    calc_pct = raw_pct_native\n",
        "                    if level_from_name and key not in max_scores_map:\n",
        "                        fallback_missing_max.append((fname, level_from_name, skill))\n",
        "                skill_calc[skill] = None if np.isnan(calc_pct) else float(round(calc_pct,4))\n",
        "\n",
        "            vals = [v for v in skill_calc.values() if v is not None]\n",
        "            overall_calc = round(float(np.mean(vals)),4) if vals else None  # <- Score Obtained\n",
        "\n",
        "            # Overall del reporte (Score %)\n",
        "            overall_report = None\n",
        "            if overall_report_col is not None:\n",
        "                overall_report = to_num(row.get(overall_report_col, np.nan))\n",
        "                if isinstance(overall_report,float) and np.isnan(overall_report):\n",
        "                    overall_report = None\n",
        "\n",
        "            # ===== NUEVAS REGLAS =====\n",
        "            applied_level = level_from_name\n",
        "            level_achieved = compute_level_achieved(applied_level, overall_calc)\n",
        "            passing_criteria = compute_passing_criteria(applied_level, overall_calc)\n",
        "\n",
        "            # Fila CSV (nuevo orden / nombres)\n",
        "            master_rows.append({\n",
        "                \"User ID\": user_id,\n",
        "                \"Test name\": exam_label,\n",
        "                \"Full name\": full_name,\n",
        "                \"Applied level\": applied_level,\n",
        "                \"Use of English\": pct_two_dec_str(skill_calc.get(\"USE OF ENGLISH\")),\n",
        "                \"Reading\":       pct_two_dec_str(skill_calc.get(\"READING\")),\n",
        "                \"Listening\":     pct_two_dec_str(skill_calc.get(\"LISTENING\")),\n",
        "                \"Writing\":       pct_two_dec_str(skill_calc.get(\"WRITING\")),\n",
        "                \"Score Obtained\": pct_two_dec_str(overall_calc),\n",
        "                \"Level Achieved\": level_achieved if level_achieved else \"N/A\",\n",
        "                \"Passing Criteria\": passing_criteria,\n",
        "            })\n",
        "            cnt += 1\n",
        "\n",
        "            # Consola: mostramos ambos overalls\n",
        "            ours_str   = pct_two_dec_str(overall_calc)\n",
        "            report_str = pct_two_dec_str(overall_report)\n",
        "            if overall_calc is None or overall_report is None:\n",
        "                status = \"N/A\"\n",
        "            else:\n",
        "                status = \"COINCIDE\" if round(overall_calc,2) == round(overall_report,2) else \"NO\"\n",
        "\n",
        "            console_overall_rows.append({\n",
        "                \"Test name\": exam_label,\n",
        "                \"User ID\": user_id,\n",
        "                \"Full name\": full_name,\n",
        "                \"Score Obtained (CSV%)\": ours_str,\n",
        "                \"OVERALL REPORTE (Score %)\": report_str,\n",
        "                \"STATUS\": status\n",
        "            })\n",
        "\n",
        "            # Promedios (primer gráfico usa Score Obtained)\n",
        "            for sk in [\"USE OF ENGLISH\",\"READING\",\"LISTENING\",\"WRITING\"]:\n",
        "                if skill_calc.get(sk) is not None: acc[sk].append(skill_calc[sk])\n",
        "            if overall_calc is not None: acc[\"OVERALL\"].append(overall_calc)\n",
        "\n",
        "            # Distribución (segundo gráfico usa Level Achieved) -> incluir N/A\n",
        "            lvl_key = level_achieved if level_achieved else \"N/A\"\n",
        "            level_counts[lvl_key] = level_counts.get(lvl_key,0)+1\n",
        "\n",
        "        print(f\"OK: {fname} → {cnt} filas integradas. [{exam_label}]\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR en {fname}: {e}\")\n",
        "        invalid_files.append(fname)\n",
        "\n",
        "# ====== Exportar CSV único ======\n",
        "if master_rows:\n",
        "    df_master = pd.DataFrame.from_records(master_rows, columns=CSV_COLS)\n",
        "    out_csv = unified_csv_name()\n",
        "    df_master.to_csv(out_csv, index=False, encoding='utf-8-sig')\n",
        "    print(f\"\\nCSV UNIFICADO generado: {out_csv} — {len(df_master)} filas.\")\n",
        "    if files and AUTO_DOWNLOAD:\n",
        "        try: files.download(out_csv)\n",
        "        except Exception as e: print(f\"No se pudo descargar {out_csv}: {e}\")\n",
        "else:\n",
        "    print(\"\\nNo se generó CSV unificado (sin filas válidas).\")\n",
        "\n",
        "# ====== Consola: Score Obtained (CSV%) vs Score (%) ======\n",
        "if console_overall_rows:\n",
        "    df_console = pd.DataFrame(\n",
        "        console_overall_rows,\n",
        "        columns=[\"Test name\",\"User ID\",\"Full name\",\"Score Obtained (CSV%)\",\"OVERALL REPORTE (Score %)\",\"STATUS\"]\n",
        "    )\n",
        "    print(\"\\n=== Verificación — Score Obtained (CSV%) vs OVERALL REPORTE (Score %) ===\")\n",
        "    print(df_console.to_string(index=False))\n",
        "\n",
        "# ====== Gráficos (barras + donut) ======\n",
        "def save_and_download(fig, fname_png, dpi=300):\n",
        "    fig.tight_layout(); fig.savefig(fname_png, dpi=dpi, bbox_inches=\"tight\"); plt.close(fig)\n",
        "    if files and AUTO_DOWNLOAD:\n",
        "        try: files.download(fname_png)\n",
        "        except Exception as e: print(f\"No se pudo descargar {fname_png}: {e}\")\n",
        "\n",
        "bar_colors = [\"#0d47a1\", \"#1565c0\", \"#1976d2\", \"#1e88e5\", \"#64b5f6\"]\n",
        "pie_colors = [\"#0d47a1\", \"#1565c0\", \"#1976d2\", \"#1e88e5\", \"#42a5f5\", \"#90caf9\", \"#b0bec5\"]\n",
        "\n",
        "uoe_avg  = np.mean(acc[\"USE OF ENGLISH\"]) if acc[\"USE OF ENGLISH\"] else np.nan\n",
        "read_avg = np.mean(acc[\"READING\"])        if acc[\"READING\"] else np.nan\n",
        "lis_avg  = np.mean(acc[\"LISTENING\"])      if acc[\"LISTENING\"] else np.nan\n",
        "wri_avg  = np.mean(acc[\"WRITING\"])        if acc[\"WRITING\"] else np.nan\n",
        "ovr_avg  = np.mean(acc[\"OVERALL\"])        if acc[\"OVERALL\"] else np.nan  # <- Score Obtained promedio\n",
        "\n",
        "cats = [\"Use of English\",\"Reading\",\"Listening\",\"Writing\",\"Overall\"]\n",
        "vals = [uoe_avg, read_avg, lis_avg, wri_avg, ovr_avg]\n",
        "\n",
        "fig1 = plt.figure(figsize=(11,5.5))\n",
        "ax = fig1.gca()\n",
        "bars = ax.bar(cats, vals, color=bar_colors)\n",
        "ax.set_ylim(0,100)\n",
        "ax.set_ylabel(\"Percentage (%)\")\n",
        "ax.set_title(\"OTCC MOCK — Integrated — Average per skill and overall. (MOCK)\", fontsize=14, pad=12)\n",
        "for b,v in zip(bars, vals):\n",
        "    if v==v:\n",
        "        ax.text(b.get_x()+b.get_width()/2, b.get_height()+1, f\"{round(v,2):.2f}%\", ha='center', va='bottom', fontsize=10)\n",
        "save_and_download(fig1, sanitize_png_name(\"OTCC MOCK — Integrated - Average per skill and overall (MOCK).png\"))\n",
        "\n",
        "# Donut: Distribution by English language level -> Level Achieved + N/A\n",
        "pairs_unsorted = [(lvl, cnt) for lvl, cnt in level_counts.items() if cnt>0]\n",
        "if not pairs_unsorted and master_rows:\n",
        "    nv = pd.Series([r[\"Level Achieved\"] for r in master_rows]).astype(str)\n",
        "    # convertir vacíos o nan a N/A\n",
        "    nv = nv.replace({\"None\":\"N/A\",\"nan\":\"N/A\",\"NaN\":\"N/A\",\"\": \"N/A\"})\n",
        "    for lvl, cnt in nv.value_counts().items(): pairs_unsorted.append((lvl, int(cnt)))\n",
        "\n",
        "if pairs_unsorted:\n",
        "    def order_key(lvl):\n",
        "        return level_order.index(lvl) if lvl in level_order else 999\n",
        "\n",
        "    pairs = sorted(pairs_unsorted, key=lambda x: order_key(x[0]))\n",
        "    labels, sizes = zip(*pairs); total = int(sum(sizes))\n",
        "\n",
        "    fig2 = plt.figure(figsize=(10,7)); ax2 = fig2.gca()\n",
        "    colors = pie_colors[:len(sizes)] if len(pie_colors) >= len(sizes) else None\n",
        "    wedges, _ = ax2.pie(\n",
        "        sizes, startangle=0, counterclock=False,\n",
        "        colors=colors,\n",
        "        wedgeprops=dict(width=0.50, edgecolor='white', linewidth=1.2)\n",
        "    )\n",
        "    ax2.text(0, 0, f\"Total\\n{total}\", ha='center', va='center', fontsize=13)\n",
        "    ax2.axis('equal')\n",
        "    ax2.set_title(\"OTCC MOCK — Integrated — Distribution by English language level (MOCK)\", fontsize=16, pad=14)\n",
        "\n",
        "    inner_r = 1.0 - 0.50\n",
        "    r_text  = inner_r + 0.25\n",
        "    for w, lbl, sz in zip(wedges, labels, sizes):\n",
        "        theta = (w.theta2 + w.theta1) / 2.0\n",
        "        ang   = np.deg2rad(theta)\n",
        "        x = r_text * np.cos(ang); y = r_text * np.sin(ang)\n",
        "        pct = 100.0 * sz / total; fz = 11 if pct >= 6 else 9\n",
        "        ax2.text(x, y, f\"{lbl} {pct:.1f}%\", ha='center', va='center',\n",
        "                 fontsize=fz, fontweight='bold', color='black')\n",
        "\n",
        "    legend_text = \"\\n\".join([f\"{lvl} = {cnt} persons at this level\" for lvl, cnt in pairs])\n",
        "    fig2.text(0.98, 0.02, legend_text, ha='right', va='bottom',\n",
        "              bbox=dict(boxstyle=\"round,pad=0.6\", facecolor=\"white\", alpha=0.95, linewidth=0.8),\n",
        "              fontsize=13)\n",
        "\n",
        "    save_and_download(fig2, sanitize_png_name(\"OTCC MOCK — Integrated - Distribution by English language level (MOCK).png\"))\n",
        "\n",
        "# ====== Calidad ======\n",
        "if invalid_files:\n",
        "    print(\"\\nArchivos descartados por no ser 'OTCC MOCK' (o con errores):\")\n",
        "    for x in invalid_files: print(\"  -\", x)\n",
        "if fallback_missing_max:\n",
        "    print(\"\\nAviso: se usó % nativo (Part X- Score(%)) por falta de max_score para:\")\n",
        "    seen=set()\n",
        "    for fname, level, skill in fallback_missing_max:\n",
        "        key=(level,skill)\n",
        "        if key not in seen:\n",
        "            print(f\"  - level={level}, skill={skill}\")\n",
        "            seen.add(key)\n",
        "\n",
        "print(\"\\nListo.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "id": "UWabPJF-RxjY",
        "outputId": "eadf6951-482d-48be-8d60-b80866fadab9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sube los reportes de AssessmentQ (puedes seleccionar varios; .csv, .xlsx o .xls).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dd559f0d-a85c-436d-ad66-2122e4355db5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dd559f0d-a85c-436d-ad66-2122e4355db5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 20260114_AssignmentReport_OTCC MOCK B1 (S0_1009).xlsx to 20260114_AssignmentReport_OTCC MOCK B1 (S0_1009).xlsx\n",
            "Saving 20260114_AssignmentReport_OTCC MOCK B2 (S0_1009).xlsx to 20260114_AssignmentReport_OTCC MOCK B2 (S0_1009).xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK: 20260114_AssignmentReport_OTCC MOCK B1 (S0_1009).xlsx → 21 filas integradas. [OTCC MOCK B1 (S0_1009)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK: 20260114_AssignmentReport_OTCC MOCK B2 (S0_1009).xlsx → 14 filas integradas. [OTCC MOCK B2 (S0_1009)]\n",
            "\n",
            "CSV UNIFICADO generado: OTCC MOCK - UNIFICADO_20260122_151637.csv — 35 filas.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c6c81269-ebcb-4337-94f9-440b75350387\", \"OTCC MOCK - UNIFICADO_20260122_151637.csv\", 3811)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Verificación — Score Obtained (CSV%) vs OVERALL REPORTE (Score %) ===\n",
            "             Test name User ID                        Full name Score Obtained (CSV%) OVERALL REPORTE (Score %) STATUS\n",
            "OTCC MOCK B1 (S0_1009) 7680190      JUAN CARLOS NARVAEZ VAZQUEZ                78.91%                    76.07%     NO\n",
            "OTCC MOCK B1 (S0_1009) 7680532         EMILIANO CASANOVA ARJONA                75.33%                    71.43%     NO\n",
            "OTCC MOCK B1 (S0_1009) 7680496      CARLOS ARTURO VARGAS PRIETO                73.09%                    70.45%     NO\n",
            "OTCC MOCK B1 (S0_1009) 7680501         LAYLA DANAHE RUIZ VARGAZ                87.64%                    88.30%     NO\n",
            "OTCC MOCK B1 (S0_1009) 7680179       CHELSEA IVANA DIAZ BELTRAN                61.54%                    57.05%     NO\n",
            "OTCC MOCK B1 (S0_1009) 7680523           VALERIA CONTRERAS RUIZ                86.38%                    87.59%     NO\n",
            "OTCC MOCK B1 (S0_1009) 7680509 JOANNA MONTSERRAT BELTRÁN CHABLÉ                76.80%                    73.39%     NO\n",
            "OTCC MOCK B1 (S0_1009) 7680192      RAMIRO RAFAEL OCAÑA BARCELÓ                75.67%                    74.38%     NO\n",
            "OTCC MOCK B1 (S0_1009) 7680516       CESAR TRINIDAD VIDAL LÓPEZ                74.64%                    74.46%     NO\n",
            "OTCC MOCK B1 (S0_1009) 7680217          DANTE ALBERTO OJEDA YAM                59.98%                    60.89%     NO\n",
            "OTCC MOCK B1 (S0_1009) 7680524         SARA JASIBE RUIZ RAMIREZ                73.23%                    71.25%     NO\n",
            "OTCC MOCK B1 (S0_1009) 7680527         MELISSA SOFIA GOMEZ CHAN                75.50%                    72.23%     NO\n",
            "OTCC MOCK B1 (S0_1009) 7680178        PAULINA NAOMI SANCHEZ CEN                77.53%                    75.00%     NO\n",
            "OTCC MOCK B1 (S0_1009) 7728871          Karin Farid Tzakum  May                78.21%                    76.34%     NO\n",
            "OTCC MOCK B1 (S0_1009) 7680195      CHRISTOPHER ELIAS LÓPEZ MIS                74.76%                    70.45%     NO\n",
            "OTCC MOCK B1 (S0_1009) 7680511        OLIVER MOISES MONGE ORTÍZ                64.32%                    68.75%     NO\n",
            "OTCC MOCK B1 (S0_1009) 7680526  XIMENA PAOLA GONZALEZ RODRIGUEZ                80.94%                    77.95%     NO\n",
            "OTCC MOCK B1 (S0_1009) 7680216                SOFIA ARPAIZ LEAL                63.90%                    58.48%     NO\n",
            "OTCC MOCK B1 (S0_1009) 7680193  VALERIA FERNANDA SALAZAR CASTRO                63.15%                    57.95%     NO\n",
            "OTCC MOCK B1 (S0_1009) 7680206            ALEJANDRO LEÓN KANTÚN                62.80%                    65.63%     NO\n",
            "OTCC MOCK B1 (S0_1009) 7680520              STACY BARRON ACOSTA                78.57%                    75.45%     NO\n",
            "OTCC MOCK B2 (S0_1009) 7680500       BRUNO SANTIAGO YAMA PATRON                   N/A                       N/A    N/A\n",
            "OTCC MOCK B2 (S0_1009) 7680529    MARIA FERNANDA HERRERA GARCIA                76.35%                    73.39%     NO\n",
            "OTCC MOCK B2 (S0_1009) 7680525   LEANDRO ANTONIO RAMOS GONZALEZ                82.75%                    80.98%     NO\n",
            "OTCC MOCK B2 (S0_1009) 7680494         ALLEN EFRÉN CHÁVEZ GARZA                74.90%                    76.25%     NO\n",
            "OTCC MOCK B2 (S0_1009) 7680505  ABRIL FERNANDA HERNÁNDEZ ORTEGA                72.68%                    74.55%     NO\n",
            "OTCC MOCK B2 (S0_1009) 7680493            EDWIN OROPEZA HERRERA                72.24%                    71.96%     NO\n",
            "OTCC MOCK B2 (S0_1009) 7680180         MIGUEL ANGEL PALMA AVILA                72.87%                    73.39%     NO\n",
            "OTCC MOCK B2 (S0_1009) 7680536  MOISES TADEO VILLANUEVA PERALTA                74.08%                    71.43%     NO\n",
            "OTCC MOCK B2 (S0_1009) 7680530         RENATHA DE DIOS CEBALLOS                78.38%                    75.27%     NO\n",
            "OTCC MOCK B2 (S0_1009) 7680528      RAMSES HELAMAN MONTERO PECH                82.69%                    81.88%     NO\n",
            "OTCC MOCK B2 (S0_1009) 7680531        BENJAMIN VELASCO MARTINEZ                72.39%                    67.95%     NO\n",
            "OTCC MOCK B2 (S0_1009) 7680508    MONICA TATIANA ITURRALDE MENA                79.17%                    77.32%     NO\n",
            "OTCC MOCK B2 (S0_1009) 7680182    IVANNA MONSERRAT AYUSO MEDINA                72.57%                    70.63%     NO\n",
            "OTCC MOCK B2 (S0_1009) 7680184     SAMUEL ADRIAN GARRIDO CANCHE                57.84%                    52.41%     NO\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3d4cb184-9d98-4b9c-ade2-e7f81fa15606\", \"OTCC MOCK \\u2014 Integrated - Average per skill and overall (MOCK).png\", 131063)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_998b98a6-2021-41cc-9679-72768bb2e194\", \"OTCC MOCK \\u2014 Integrated - Distribution by English language level (MOCK).png\", 238522)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Listo.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}